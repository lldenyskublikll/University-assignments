# -*- coding: utf-8 -*-
"""STDINNS lab 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sMBZvqfZQwF1e-ZjZPt5bsAl32AU_BMa
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import utils
from keras.models import Sequential
from keras.layers import Dense, Flatten
from keras.datasets import mnist

"""#Prepare and display dataset

"""

# Downloading mnist dataset
(image_train,  value_train), (image_test, value_test) = mnist.load_data()

# Displaying the part of mnist dataset
def display_dataset(x, y):
    plt.figure(figsize = (15, 15))
    for i in range (25):
        plt.subplot(5, 5, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(image_train[i])
        plt.xlabel(f'Value: {value_train[i]}')
    plt.show()

display_dataset(image_train, value_train)

# Preparing dataset for NN training
image_train = image_train.astype('float32') / 255.0
image_test= image_test.astype('float32') / 255.0

value_train = utils.to_categorical(value_train, 10)
value_test = utils.to_categorical(value_test, 10)

"""#Create and train model"""

# Function for sequential model creation
def create_model():
    # Sequential model creation
    model = Sequential([Flatten(input_shape = (28, 28)),
                        Dense(32, activation = 'relu'),
                        Dense(10, activation = 'softmax')])
    # Displaying the information about model
    model.summary()

    # Compiling model
    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

    return model

# Function for model training
def train_model(model, epochs, batch):
    # Training
    history = model.fit(image_train, value_train, epochs = epochs,
                        batch_size = batch, validation_split = 0.1)

    # Getting info about training loss and accuracy
    test_loss, test_accuracy = model.evaluate(image_test, value_test)

    return history, test_loss, test_accuracy

# Function for plotting graps with statistics
def show_loss_n_accuracy_info(history):
    # Plotting "Loss over time" graph
    plt.plot(history['loss'], label = 'Training loss')
    plt.plot(history['val_loss'], label = 'Validation loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('"Loss over time" graph')
    plt.legend()
    plt.show()

    # Plotting "Accuracy over time" graph
    plt.plot(history['accuracy'], label = 'Training accuracy')
    plt.plot(history['val_accuracy'], label = 'Validation accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('"Accuracy over time" graph')
    plt.legend()
    plt.show()

# Function for model prediction tests
def test_model_predictions_for_rnd_elements(model, x_test, y_test, samples = 10):
    # Getting 10 random element indexes from test part of the mnist dataset
    random_index = np.random.choice(x_test.shape[0], size = samples, replace = False)

    # Displaying all random elements from test part pf the mnist dataset with their actual values
    print("=========================================================================\n=========================================================================")
    print("10 random elements of test dataset:")
    counter = 0
    plt.figure(figsize = (15, 15))
    for i in random_index:
        counter += 1
        plt.subplot(5, 5, counter)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(x_test[i])
        prediction = model.predict(x_test[i:i + 1])
        print("Prediction:", np.argmax(prediction), "\n")
        plt.xlabel(f"Actual value: {np.argmax(y_test[i])} | Prediction: {np.argmax(prediction)}")
    plt.show()

    # Displaying random elements from test part of the mnist dataset one-by-one with their actual values and model predictions
    print("=========================================================================\n=========================================================================")
    print("Predictions for each element:")
    for i in random_index:
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(x_test[i])
        plt.xlabel(f'Actual value: {np.argmax(y_test[i])}')
        plt.show()
        prediction = model.predict(x_test[i:i + 1])
        print(f"Prediction: {np.argmax(prediction)}\n")

"""#Main"""

# Main part of the code that uses all created functions
if __name__ == "__main__":
    # New sequential model creation
    model = create_model()

    # Training model and getting training history, testing loss and accuracy
    train_history, test_loss, test_accuracy = train_model(model, 40, 200)
    print('==================================================================================================================================')
    print(f'Test loss: {test_loss}')
    print(f'Test accuracy: {test_accuracy}')
    print('==================================================================================================================================')

    # Distplaying stats
    show_loss_n_accuracy_info(train_history.history)

    # Viewing model predictions on 10 randon elements from test part of mnist dataset
    test_model_predictions_for_rnd_elements(model, image_test, value_test)

"""# Test zone"""

random_index = np.random.choice(image_test.shape[0], size = 10, replace = False)
print(random_index)
print(random_index[1])

for i in random_index:
    print(i)

test_shit = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
for i in test_shit:
    print(i)

plt.figure(figsize = (15, 15))
j = 0

for i in test_shit:
    j += 1
    plt.subplot(5, 5, j)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(image_test[i])
    plt.xlabel(f'Actual value ({i}): {np.argmax(value_test[i])}')
plt.show()